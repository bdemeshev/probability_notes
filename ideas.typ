#set page(paper: "a4")
#set heading(numbering: "1.")

#show link: set text(fill: blue, weight: 700)
#show link: underline


= Формат

Публикация отдельных глав в виде номеров журнала. Или в каком-то журнале?
Итоговая книга в виде сборника, как подборки квантика. 


Чистые листы и карандаш внутри книги. 
Стираемая одна страничка, вкладыш. Ручка. 

Книга как объект искусства. 

Основной формат: hmtl vs pdf? epub?

В цвете. Забота о тех, кто плохо видит. 

Tufte handout. 

От Димы Борзых: выпускать частями. Часть 1. Часть 2. Полная версия. 

Мини-главы в виде плакатов на стену! Хорошее проектное дз. На русском и английском. 
Под открытой лицензией. Тоже typst.

Публикация мини-главы в виде цветного складываемого глянцевого листа А3. 

Больше классических задач из разных областей знания.

Литературная (научная) мистификация? Скрытый автор? 

Сквозная художественная история-драма в задачах?

= Название 

Название. Probability with love. For the love of probabilities. Тост? За счастье теории вероятностей?


= Идеи без разбора

Подборка книг и статей для вдохновения в доступе. Составить книг список по https://math.stackexchange.com/. Посмотреть список курсов ведущих университетов. 


Сердечко как модификатор предельного отношения. Точка у Фихтенгольца. Шрифт с несколькими разными сердечками, похожими на нарисованные от руки.


Резюме в конце главы с определениями, формулировками теорем, обозначениями, краткими формулировками идей. 



Иногда: красивые фото природы, красивые доказательства без слов. Почему? Мы их заодно популяризируем! Особенно, если они уместны к задаче! Вдруг там упоминается какое-то арифметическое свойство. 

Периодическая, раз в 10 страниц, страница — отвлекалочка: фото природы, доказательства без слов, ссылки на интересные математические ресурсы: https://math.stackexchange.com/, Keith Conrad, https://kconrad.math.uconn.edu/blurbs/, Evan Chen, ... Возможно, стихотворение, ссылка на музыку для решения, мемасик, байка про математика. 

Конечно, можно какие-то из этих вещей к месту делать, но есть такие, которые не совсем понятно, куда подкрепить. 

Большая картинка с мелкими деталями, персонажами, и загадками? 

Подробно говорить, как читается новое определение. 
Рассказывать, как оно пишется в латехе. 

Скажем, прямо стандартный шаблон?

[сигма-алгебра, порождённая множеством $A$]
...
тело определения
...
обозначение: $sigma(A)$
традиционные буквы: каллиграфические, $F$, $H$
латех: \mathcal{H}, обычно в преамбуле вводят сокращение \newcommand{\cF}{\mathcal{F}}. 


Длинные текстовые доказательства: как их оформлять? Обычно пишут в начале «доказательство» и в конце — квадратик. 
Возможно, узкий растительный орнамент сбоку? с цветными красными цветочками и зелёными листиками? косичка? 
арабские узоры? армянские? грузинские? китайская или японская сказка?


Задачи на стыке жанров:
- звонок Си на китайском
- вставка текста на татарском в задаче
- задача про вероятность верного ответа про тест по теории вероятностей: несколько вариантов
- задача с цензурой


Нелинейность изложения. География изложения. Карта «где я?» периодически, как указательный знак на тропе в горах. 
Схема утверждений от текущего к доказываемым с разными вариантами доказательства. Оформление? Сбоку выделить цветом на чёрно-белой карте текущий отрезок пути? Посмотреть, как оформляют схемы дорог в реальности?


Картинки только с мелкими дополнительными детальками. Не просто плотность нормального распределения, а где-то на ней обязательно сидит ёжик. 


Границы дисциплины можно нарушать! Можно включить геометрическое нахождение производных, теорию игр!


Рассказывать некрасивые задачи с кудряшками, если я считаю, что кудряшки бесполезны, но задачи с кудряшками могут встретиться в других курсах? 

Рассказать новое идейное решение и классическое решение затем.

Задачи на поиск ошибок? Задачи на корректную интерпретацию некорректных задач? Задачи на педагогическую переформулировку? Учит ли учебник педагогике?

Если график сложный, то рисовать его как комикс серией картинок. Или анимация в html?


= Оформление 

Диковинные птицы и цветы. Here be dragons. Средневековые маргиналиии. 
Буквицы.


= Цепи Маркова

Начать с цепей Маркова!

Идеи: позиция. Будущее зависит от позиции, а не от предыстории!
Определение позиции зависит от вопроса. Для одних вопросов важно хранить одну информацию, для других — другую.
Задача-шутка. Сколько было остановок?
Идея: цена/стоимость позиции. Стоимостью позиции может быть что-угодно.
Метод первого шага. Очень классная задача про кубик и деньги в шляпе.
От каких переменных и как качественно зависит стоимость позиции? 
Можно обсудить идеи: стоимость игры с пустым началом, курс рубля в шляпе. 
Можно модифицировать игру так, чтобы легко найти курс рубля в шляпе, например, можно отказаться от получения новых рублей в шляпу. 


Цепь Маркова. Как дать незанудное определение «направленный граф...»? А нужно ли давать определение?
Множество позиций, для которого:
- указаны стрелочками все возможные переходы между состояниями.
- сумма вероятностей на исходящих стрелочках из каждого состояния равна единице.

Если игра оканчивается в каком-то узле, то можно считать, что игра «залипает» в нём и провести стрелочку из этого финального узла обратно к нему же.
Здесь две картинки: слева до дорисовывания стрелочек в финальных узлах, справа — после дорисовывания. 

Парадокс Эльхалана Мосселя с помощью метода первого шага. 




= Слова как производящие функции

Лучшее пари для простаков.
Числа Фибоначчи. Важность графа для иллюстрации. Ребро = дописывание буквы. Вершина = слово. 
Кнопка play или пустой квадратик в начале? 

Парадокс Эльхалана Мосселя с помощью слов и подстановок.

С помощью слов можно описать: множество всех исходов, событие, множество событий. 
Особый пример: множество неоконченных траекторий эксперимента. 



Отсылка к Пойя, On picture-writing.
Wilf, Generatingfunctionology.  

= Определение вероятности 

Сразу потребовать непрерывность от вероятности в определении?

Задача о злобном деде Морозе. 
Задача о телескопической сумме, вероятностная интерпретация. 



Временные определения. 
Например. Условное ожидание по случайной величине — функция от $X$, минимизирующая ожидаемый квадрат ошибки. 


Симуляции. Вероятностное программирование для безусловных вероятностей?
А потом для условных дискретных? Вероятностная графическая модель: показывает, в каком порядке можно рассчитывать величины. 



= Изображение распределений

Дискретное. Отрезками с точечкой сверху от числовой прямой значений. 
Отрезки для удобства можно превратить в столбики, но надо быть осторожным, значения могут «сгущаться».
Отрезки можно расположить один сверху другого, тогда они сложатся в отрезок длины один, а положительные значения величины отложить вправо. Мы получаем способ генерировать величину исходя из равномерной. 

Изображаем математическое ожидание на двух графиках: центр масс и площадь. 
Тут связка с перегородками и доской с песком? Только песок вниз падает, а тут повёрнутый график. Нарисовать оба с поворотом?


Почему любую величину можно получить из равномерной? Но не через формульное обращение функции распределения!
Надо нарисовать сначала для дискретных два графика рядом: с разбитыми отрезками растущими от значений, а потом склеенными и соответствием.
Потом нарисовать плотность слева и справа отрезок. И значение в точке — значение с заданной закрашенное плотностью справа. Площадь слева превращена в длину справа. 

Описали правую границу множества, как преобразующую (слово?) функцию, нижнюю границу — как вероятность.
Точки и стрелочки. Непрерывность справа у распределения и слева у квантильной функции.

Связка с трактовкой величины как вероятности. 



= Трактовка случайной величины на отрезке $[0, 1]$ как вероятности

Допустим $X_((1))$ — это минимум из $n$ равномерных на $[0; 1]$ независимых случайных величин, $X_((1)) = min{X_1, X_2, ..., X_n}$. 
Найдём $E(X_((1)))$ и $E(X_((1))^2)$.


$ E(X_((1))) = E[P(Y_1 < X_((1)) | X_((1)))] = P(Y_1 < X_((1))) = P(Y_1 < X_1, X_2, .... X_n) = 1/(n+1). $

$ E(X_((1))^2) = E[P(Y_1 < X_((1)); Y_2 < X_((1)) | X_((1)))] = P(Y_1, Y_2 < X_((1))) = P(Y_1, Y_2 < X_1, X_2, .... X_n) = 1/C_(n+2)^2. $


Найдём $E(X_((3)) X_((7)))$:

$ E(X_((3)) X_((7))) = E[P(Y_1 < X_((3)); Y_2 < X_((7)) | X_((3)), X_((7)))] = P(Y_1 < X_((3)); Y_2 < X_((7))) = \ 
= P(Y_1 < X_((3)); Y_2 < X_((3))) + P(Y_1 < X_((3)); X_((3)) < Y_2 < X_((7))) = frac(4, 17) dot frac(3, 16) + frac(4, 17) dot frac(4, 16) $.

Закончить вычисления можно и переходом к условным вероятностям:

$ P(Y_1 < X_((3)); Y_2 < X_((7))) = P(Y_1 < X_((3))) dot P(Y_2 < X_((7)) | Y_1 < X_((3))) = frac(4, 17) dot frac(7, 16) $ 



Найдём $E(L_2 L_7)$...





= Сигма-алгебры и условное ожидание

Дать сначала определение порождённой сигма-алгебры.

Набор событий называется $sigma$-алгеброй, порождённой событием $A$, если выполнены свойства:

1. Тривиальные события $Omega$ и $emptyset$ принадлежат набору. 
2. Событие $A$ принадлежит набору. 
3. Набор содержит любое событие $B$, которое можно сконструировать из счётного количества других событий набора
с помощью любых операций с множествами (объединение, пересечение, дополнение). 
4. Набор является наименьшим возможным. 

Пример. Найдём $sigma(A)$.

Сигма-алгебра обозначается $sigma(A)$. Аналогично, можно дать определение сигма-алгебры порождённой несколькими событиями. 

Потом сигма-алгебра, порождённая случайной величиной. Или сначала именно случайной величиной? Важны же именно они!


Потом уже сказать про абстрактную сигма-алгебру. 




Картинки для сигма-алгебр с объединением слипшихся неотличимых исходов чёрточками.

Закон распределения случайной величины в виде гирек на оси, с подписанными вероятностями и исходами на каждой гирьке. Сигма-алгебра задаёт объединение некоторых гирек в их центре масс. Можно ставить общую карточную масть у объединяемых гирек. 

Сначала сформулировать $E(Y) = E(E(Y \mid \cF))$, а потом сказать, что мы это свойство используем как аксиому для определения условного ожидания. Общий центр масс не изменяется при объединении некоторых гирек. 

Картинка с песком на плоскости, разделённым палочками и $E(Y\mid \cF)$ по вертикали. 


= Покажи мне dx!


Из подобия треугольников находим, что

$frac(d x, d phi) = -y$, $frac(d y, d phi) = x$.


Власти скрывают, что арккосинус нужно считать от $x$, а арксинус — от $y$!




= Нормальное распределение

Представим себе, что мы поймали одну из молекул кислорода, летающую в закрытой комнате. 
У пойманной молекулы есть вектор скорости из трёх компонент, $(X, Y, Z)$. 
Что логично предположить про закон распределения этого вектора?

Комната закрыта, ветра в ней нет, поэтому можно предположить, что молекулы движутся случайно, не предпочитая ни одно из направлений. 
Это означает, что при повороте вектора на фиксированный угол его закон распределения не изменяется. 




Для простоты дальнейшего изложения будем считать, что комната плоская и у пойманной молекулы всего две компоненты скорости, $(X, Y)$.

$ f(x) f(y) d x d y = f(x, y) d A $
Сокращаем $d A = d x d y$ и логарифмируем:
$ ln f(x) + ln f(y) = ln f(x, y). $
Замечаем, что для распределения инвариантного к повороту ни левая, ни правая части не зависит от угла $phi$.
Продифференцируем по углу $phi$.
$ frac(f'(x), f(x)) dot frac(d x, d phi) + frac(f'(y), f(y)) dot frac(d y, d phi) = 0 $
Или 
$ frac(f'(x), f(x)) dot (-y) + frac(f'(y), f(y)) dot x = 0 $
Разнесём $x$ и $y$ по разным частям уравнения
$ frac(f'(x), f(x)) dot y = frac(f'(y), f(y)) dot x $
Или
$ frac(f'(x), x f(x)) = frac(f'(y), y f(y)) $
Это возможно равенство возможно для произвольных значений $x$ и $y$, только если обе стороны тождественно равны константе. 




... получаем опорное дифференциальное уравнение (!)

Начальное условие: площадь равна единице. $f(0) = frac(1, sqrt(2 pi))$.

Из уравнение: быстрота убывания, точки перегиба, график, лемма Стейна, $E(abs(X))$, решение уравнения.

График, иллюстрирующий быстроту убывания, парабола под графиком плотности, шаг по вертикали $2 ln(2) approx 1.4$.

Нахождение константы: графическое свойство экспоненты: площадь и длина тени касательной. Принцип Мамикона. 




= Оптимизация

Раздел по оптимизации. Правило Брусса. Задача о невесте. Задача о подружке невесты. 
Оптимизация стационарных стратегий с методом первого шага.
Задача об истеричной певице. Условная энтропия и критерий Келли. 
Индексы Гиттингса. 


= Уроборос или склейка

Метод с зацикливанием отрезка или колоды карт = уроборос. Картинка.
Метод склейки? Вставки?

= Разложение в сумму 

Лирические отступления в сторону. Интегрирование. Сложение = телескопическая сумма. 
Полином по базису $C^2_n$ для производящей функции. Полином по базису клюшек для конечных сумм. 

Картинка: Слон = туловище + уши-хвост. 
А можно и на три составляющих: слон = туловище + уши + хвост.


= Мартингальный метод 

Классный повод рассказать про мартингалы. Сначала ввести мартингал без сигма-алгебр. 
Мотивация условий теоремы Дуба через сходимость. 
Задача о мартышке и АБРАКАДАБРА. Сговор с мартышкой и предварительно написанное слово. 
Вероятности для первой последовательности — линейная система уравнений по Li, pattern... martingales. 


= Бесконечно малые

Вероятности по картинке? 
Вероятностные бесконечно малые? Задачи именно на них?

= Инфинитезимальные вероятности 

Глава по мотивам инфинитезимального подхода к винеровскому и пуассоновскому процессу, по Radically Elementary Probability Theory. 
Hackenbush, surreals, hyperreals...
Сильное равновесие в теории игр. 

= Винеровский процесс 

Выйти от винеровского процесса к нормальному распределению в третий раз!
Предположим, что есть какое-то распределение, полностью описываемое ожидаемым значением и дисперсией. 
Предположим, что приращения броуновского движения не зависимы. 
Далее выход на нормальное распределение через Landon. 
http://www-biba.inrialpes.fr/Jaynes/cc07s.pdf


И в целом идти от Пуассоновского процесса к Пуассоновской и экспоненциальной случайной величинам??




= Программирование

Писать ли коды? Питон ли?


=


= html

No tracking. Уважаем приватность! Без cookies. 

Тиражируемые задачи с автопроверкой. 
Зерно генератора, которое можно указать для каждой задачи. И просто кнопочка «далее» — даёт следующую версию задачи. 

Задачи в pdf версии содержат маленький qr код на тиражируемую html задачу. 



= Max Lik в теории вероятностей

Идея Гаусса. Инвариантность и неинвариантность. Пример, когда правдоподобие несостоятельно с точками.
Задача про новые виды (две версии). Задача о немецких танках. 
https://math.stackexchange.com/questions/3777463/how-to-estimate-total-number-of-different-results-for-a-stochastic-event
https://math.stackexchange.com/questions/242607/estimate-number-of-distinct-items



= Аксиома выбора

Парадоксы про аксиому выбора. Равномерное распределение не существует. 
Варианты: в рассуждении выше ошибка, равномерное распределение не существует, не у всех множеств есть вероятность?

Парадокс с множеством не содержащим себя. Какие же есть правила построения множеств?

Вторая необходимость сигма-алгебр! Первая — информация!





= Тесты в теории вероятностей!

Множественное тестирование. Идея ошибок первого и второго рода сразу в вероятностях!

Две идеи. Генерация данных по нулевой модели и сравнение этих результатов с нашими. Генерация данных по нашей модели и сравнение этих результатов с типичным нулевым. Почему в бутстрэпе берут не случайные нулевой результат, а ожидаемый?
Перестановочный тест. 



= Источники

тэг \#prob_source в calibre

todo: поискать нестандартные (!) учебники по вероятностям

todo: понять, какие учебники используются при реальном преподавании. 
Когда открытый учебник будет готов, написать письма разным лекторам?

https://disk.yandex.ru/d/Wv6fbnY3L0J1dQ
Станислав Морозов, фкн, основной поток

https://disk.yandex.ru/d/IWrhIV8colz2sw
Дмитрий Шабанов, Алина Хузиева, фкн, пилотный поток


http://www.alternatievewiskunde.nl/QED/normal.pdf
Вывод нормального распределения с малыми приращениями. Немного похоже на Гершеля-Максвелла. 


Hamming, The art of probability
Необычный учебник по теории вероятностей. Куча примеров, оглавление идёт по примерам! Мотивация распределений и другие вкусности!
Тот самый Хэмминг!

Jaynes, The logic of science. 

Williams, Weighing the odds 


https://news.rambler.ru/incidents/55745593-v-omske-rabotnitsa-kioska-podozrevaetsya-politsiey-v-krazhe-1-400-lotereynyh-biletov/
Суровый сибирский закон больших чисел
От судьбы не уйти?
Чему быть, того не миновать?


= Цитаты

«Более всего крестьяне любят охотно слушать рассказы о войне, в особенности о богатырях и о путешествиях. 
От таких рассказов, в которых описывается о науках, нововведениях и т.д., крестьяне зевают и уходят».

АРЭМ. Ф. 7. О. 1. Д. 28. Л. 36.


